{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621\n",
      "1672\n",
      "accuracy:\n",
      "0.9694976076555024\n",
      "precision:\n",
      "0.9868421052631579\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Stems words to their root words and removes all characters that are not alphabets\n",
    "def stem_str(str):\n",
    "    ret_str = \"\"\n",
    "    for w in word_tokenize(str.lower()):\n",
    "        if w not in stop_words and w.isalpha():\n",
    "            ret_str = ret_str + \" \" + ps.stem(w)\n",
    "    return ret_str.strip()\n",
    "\n",
    "# Gets the count of most frequent words give a dataframe\n",
    "def word_freq(df):\n",
    "    word_frequency = {}\n",
    "    for index,row in df.iterrows():\n",
    "        for w in word_tokenize(row['stemmed_sms']):\n",
    "            if w not in word_frequency:\n",
    "                word_frequency[w] = 1\n",
    "            else:\n",
    "                word_frequency[w] += 1\n",
    "    return word_frequency\n",
    "\n",
    "\n",
    "#TRAIN - outter, runs once on training data\n",
    "def train(trainData):\n",
    "    global pA\n",
    "    global pNotA\n",
    "    total = 0\n",
    "    numSpam = 0\n",
    "    #for row in trainData.rows:\n",
    "    for index, row in trainData.iterrows():\n",
    "        #print(row['category'])\n",
    "        if row['category'] == 'spam':\n",
    "            numSpam += 1\n",
    "            #print(numSpam)\n",
    "        total += 1\n",
    "        processText(row['stemmed_sms'], row['category'])\n",
    "    pA = numSpam/float(total)\n",
    "    pNotA = (float(total) - float(numSpam))/float(total)\n",
    "\n",
    "#TRAIN - inner 1, counts the words in a specific text\n",
    "def processText(body, label):\n",
    "    global negativeTotal\n",
    "    global positiveTotal\n",
    "    global numWords\n",
    "    #for word in body:\n",
    "    for word in word_tokenize(body):\n",
    "        if label == 'spam':\n",
    "            #print('spam - in')\n",
    "            trainPositive[word] = trainPositive.get(word, 0) + 1\n",
    "            positiveTotal = positiveTotal + 1\n",
    "        else:\n",
    "            trainNegative[word] = trainNegative.get(word, 0) + 1\n",
    "            negativeTotal = negativeTotal + 1\n",
    "    #print(negativeTotal)\n",
    "    #print(positiveTotal)\n",
    "\n",
    "#gives the conditional probability p(B_i | A_x)\n",
    "def conditionalWord_noSmoothing(word, spam):\n",
    "    #print('in conditional word')\n",
    "    if spam:\n",
    "        return trainPositive[word]/float(positiveTotal)\n",
    "    return trainNegative[word]/float(negativeTotal)\n",
    "\n",
    "#gives the conditional probability p(B_i | A_x) with smoothing (alpha = 1.0 for Laplace)\n",
    "def conditionalWord(word, spam, numWords):\n",
    "    alpha = 1.0 \n",
    "    if spam:\n",
    "        return (trainPositive.get(word,0)+alpha)/float(positiveTotal+alpha*numWords)\n",
    "    return (trainNegative.get(word,0)+alpha)/float(negativeTotal+alpha*numWords)\n",
    "\n",
    "\n",
    "#gives the conditional probability p(B | A_x)\n",
    "def conditionalText(body, spam, numWords):\n",
    "    result = 1.0\n",
    "    for word in word_tokenize(body):\n",
    "        result *= conditionalWord(word, spam, numWords)\n",
    "    return result\n",
    "\n",
    "#classifies a new text as spam or not spam\n",
    "def classify(text,numWords):\n",
    "    isSpam = pA * conditionalText(text, True, numWords) # P (A | B)\n",
    "    notSpam = pNotA * conditionalText(text, False, numWords) # P(Â¬A | B)\n",
    "    return isSpam > notSpam\n",
    "\n",
    "    \n",
    "#reading in the data and renaming columns    \n",
    "data = pd.read_csv('./spam.csv',encoding = \"ISO-8859-1\")\n",
    "data.columns = ['category', 'text']\n",
    "\n",
    "#stem data\n",
    "data['stemmed_sms'] = data.loc[:,'text'].apply(lambda x: stem_str(str(x)))\n",
    "#print(data)\n",
    "\n",
    "#split data into training and test data\n",
    "#trainData, test = train_test_split(data, train_size=0.20)\n",
    "trainData, test = train_test_split(data, test_size=0.30)\n",
    "\n",
    "unique_words = word_freq(data)\n",
    "\n",
    "#variable initialization\n",
    "negativeTotal = 0\n",
    "positiveTotal = 0\n",
    "trainNegative = {}\n",
    "trainPositive = {}\n",
    "pA = float(0)\n",
    "pNotA = float(0)\n",
    "resultsCorrect = 0\n",
    "totalResults = 0\n",
    "falsePositives = 0\n",
    "\n",
    "#call train function to train model\n",
    "#train(trainData)\n",
    "\n",
    "# 10 fold cross validation, not great for accuracy\n",
    "kf = KFold(n_splits=10)\n",
    "sumAccuracy = 0\n",
    "sumPrecison = 0\n",
    "for result in kf.split(data):\n",
    "    resultsCorrect = 0\n",
    "    totalResults = 0\n",
    "    falsePositives = 0\n",
    "    \n",
    "    #result = next(kf.split(data), None)\n",
    "    train_data = data.iloc[result[0]]\n",
    "    test_data =  data.iloc[result[1]]\n",
    "    \n",
    "    #print(train)\n",
    "    \n",
    "    train(train_data)\n",
    "    for index, row in test_data.iterrows():\n",
    "        result = classify(row['stemmed_sms'],len(unique_words))\n",
    "        if (result and strCategory == 'spam') or (result == False and strCategory == 'ham'):\n",
    "            resultsCorrect += 1\n",
    "        if (result == False and strCategory == 'spam'):\n",
    "            falsePositives += 1\n",
    "        totalResults += 1\n",
    "    sumAccuracy += resultsCorrect/totalResults \n",
    "    sumPrecison += (totalResults-falsePositives)/totalResults\n",
    "avgAccuracy = sumAccuracy/10\n",
    "avgPrecison = sumPrecison/10\n",
    "\n",
    "print('accuracy:')\n",
    "print(avgAccuracy)\n",
    "print('precision:')\n",
    "print(avgPrecison)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619\n",
      "1672\n",
      "accuracy:\n",
      "0.9683014354066986\n",
      "precision:\n",
      "0.9904306220095693\n"
     ]
    }
   ],
   "source": [
    "train(trainData)\n",
    "resultsCorrect = 0\n",
    "totalResults = 0\n",
    "falsePositives = 0\n",
    "\n",
    "#if result (from classify function) is TRUE means SPAM, if result is FALSE means HAM\n",
    "for index, row in test.iterrows():\n",
    "    result = classify(row['stemmed_sms'],len(unique_words))\n",
    "    strResult = str(result)\n",
    "    strCategory = str(row['category'])\n",
    "    toPrint = \"{} {} \".format(strResult, strCategory) \n",
    "    #print(toPrint)\n",
    "    if (result and strCategory == 'spam') or (result == False and strCategory == 'ham'):\n",
    "        resultsCorrect += 1\n",
    "    if (result == False and strCategory == 'spam'):\n",
    "        falsePositives += 1\n",
    "    totalResults += 1\n",
    "    \n",
    "print(resultsCorrect)\n",
    "print(totalResults)\n",
    "print('accuracy:')\n",
    "print(resultsCorrect/totalResults)\n",
    "#false positive rate\n",
    "print('precision:')\n",
    "print((totalResults-falsePositives)/totalResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
